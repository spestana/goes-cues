{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge CUES observations into a single file\n",
    "\n",
    "From directories of CUES radiation and temperature level 1 csv files, align and merge while doing some data cleanup. Save out as a pandas dataframe to a pickle file. (**Note**: CUES data are in UTC-8)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "#import datetime as dt\n",
    "import pytz\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListOfFiles(dirName):\n",
    "    # create a list of file and sub directories \n",
    "    # names in the given directory \n",
    "    # https://thispointer.com/python-how-to-get-list-of-files-in-directory-and-sub-directories/\n",
    "    listOfFile = os.listdir(dirName)\n",
    "    allFiles = list()\n",
    "    # Iterate over all the entries\n",
    "    for entry in listOfFile:\n",
    "        # Create full path\n",
    "        fullPath = os.path.join(dirName, entry)\n",
    "        # If entry is a directory then get the list of files in this directory \n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + getListOfFiles(fullPath)\n",
    "        else:\n",
    "            allFiles.append(fullPath)\n",
    "                \n",
    "    return allFiles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Open data files\n",
    "\n",
    "Specify directories containing CUES Level 1 csv files for radiation and temperature data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_directory = r'\\\\j-lundquist-3.ce.washington.edu\\storage\\CUES\\Level 1 - Database\\temperature'\n",
    "rad_directory = r'\\\\j-lundquist-3.ce.washington.edu\\storage\\CUES\\Level 1 - Database\\radiation'\n",
    "snowdepth_directory = r'\\\\j-lundquist-3.ce.washington.edu\\storage\\CUES\\Level 1 - Database\\snowdepth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the CUES temperature data files, and concatenate them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the files in this directory we'll want to open\n",
    "cues_temp_files = getListOfFiles(temp_directory)\n",
    "\n",
    "# Open all the files and concat together in a pandas dataframe\n",
    "cues_temp_data = []\n",
    "_ = [cues_temp_data.append(pd.read_csv(i)) for i in cues_temp_files]\n",
    "cues_temp_data = pd.concat(cues_temp_data)\n",
    "\n",
    "# Convert the 'DateTime' text strings to pandas datetime objects (this is UTC-8)\n",
    "cues_temp_data['datetime']  = pd.to_datetime(cues_temp_data['MeasDateTime'])\n",
    "\n",
    "#Convert pandas dataframe to xarray dataset and and make our local time datetimes the index\n",
    "_cues_temp_data = cues_temp_data.set_index('datetime')\n",
    "_cues_temp_data.sort_index(inplace=True)\n",
    "cues_ds = _cues_temp_data.to_xarray()\n",
    "\n",
    "# drop old time field\n",
    "cues_ds = cues_ds.drop_vars(names='MeasDateTime')\n",
    "\n",
    "# select only the unique datetime indices we have now (But why are there duplicates and where are they?)\n",
    "_, index = np.unique(cues_ds['datetime'], return_index=True)\n",
    "cues_ds = cues_ds.isel(datetime=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the CUES radiation data files, and concatenate them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the files in this directory we'll want to open\n",
    "cues_rad_files = getListOfFiles(rad_directory)\n",
    "\n",
    "# Open all the files and concat together in a pandas dataframe\n",
    "cues_rad_data = []\n",
    "_ = [cues_rad_data.append(pd.read_csv(i)) for i in cues_rad_files]\n",
    "cues_rad_data = pd.concat(cues_rad_data)\n",
    "\n",
    "# Convert the 'DateTime' text strings to pandas datetime objects (this is UTC-8)\n",
    "cues_rad_data['datetime']  = pd.to_datetime(cues_rad_data['MeasDateTime'])\n",
    "\n",
    "# Convert pandas dataframe to xarray dataset and and make our local time datetimes the index\n",
    "_cues_rad_data = cues_rad_data.set_index('datetime')\n",
    "_cues_rad_data.sort_index(inplace=True)\n",
    "cues_rad = _cues_rad_data.to_xarray()\n",
    "\n",
    "# drop old time field\n",
    "cues_rad = cues_rad.drop_vars(names='MeasDateTime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the CUES snow depth data files, and concatenate them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the files in this directory we'll want to open\n",
    "cues_snowdepth_files = getListOfFiles(snowdepth_directory)\n",
    "\n",
    "# Open all the files and concat together in a pandas dataframe\n",
    "cues_snowdepth_data = []\n",
    "_ = [cues_snowdepth_data.append(pd.read_csv(i)) for i in cues_snowdepth_files]\n",
    "cues_snowdepth_data = pd.concat(cues_snowdepth_data)\n",
    "\n",
    "# Convert the 'DateTime' text strings to pandas datetime objects (this is UTC-8)\n",
    "cues_snowdepth_data['datetime']  = pd.to_datetime(cues_snowdepth_data['MeasDateTime'])\n",
    "\n",
    "# Convert pandas dataframe to xarray dataset and and make our local time datetimes the index\n",
    "_cues_snowdepth_data = cues_snowdepth_data.set_index('datetime')\n",
    "_cues_snowdepth_data.sort_index(inplace=True)\n",
    "cues_snowdepth = _cues_snowdepth_data.to_xarray()\n",
    "\n",
    "# drop old time field\n",
    "cues_snowdepth = cues_snowdepth.drop_vars(names='MeasDateTime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Merge datasets\n",
    "\n",
    "Merge the rad and temp datasets together, then save out to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should merge cleanly now\n",
    "cues_ds = xr.merge([cues_ds, cues_rad, cues_snowdepth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to pandas dataframe, save out to pickle file\n",
    "cues_ds.to_dataframe().to_pickle('CUES_L1_Temp_Rad_Snowdepth_2017-2020.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
