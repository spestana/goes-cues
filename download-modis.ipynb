{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a csv file with all the date/times of ASTER observations I'm using, and I want to now download all the MODIS (MOD021KM) imagery for the same date/times covering the same spot.\n",
    "\n",
    "I'm using the Earthdata API because doing this through their web portal would be a slow and cumbersome process.\n",
    "\n",
    "Some references:\n",
    " * [Earthdata API](https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html)\n",
    " * [MOD021KM product](https://ladsweb.modaps.eosdis.nasa.gov/missions-and-measurements/products/MOD021KM/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import io\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the ASTER images that I have saved, make a list of them and their timestamps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory all my ASTER images are in\n",
    "aster_directory = \"/storage/spestana/ASTER/AST_L1T/geotiff/T/T_band14_Tuolumne-and-CUES/\"\n",
    "\n",
    "# Find all our ASTER files and their timestamps in our directory\n",
    "aster = aster_utils.aster_timestamps(aster_directory, ext='tif')\n",
    "\n",
    "# Add a UTC-8 datetime for pacific standard that CUES uses\n",
    "aster['datetime'] = aster.timestampUTC - pd.Timedelta(hours=8)\n",
    "\n",
    "# Save a csv file of the ASTER files we are using\n",
    "#aster.to_csv('aster_AST_L1T_band14_Tuolumne-and-CUES.csv')\n",
    "\n",
    "# Alternatively, if I already have a csv file somewhere with the ASTER timestamps I want, read it in\n",
    "#aster = pd.read_csv('aster_AST_L1T_band14_Tuolumne-and-CUES.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up some of the granule search criteria for Earthdata search API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://cmr.earthdata.nasa.gov/search/granules.csv?\" #\"https://cmr.earthdata.nasa.gov/search/collections?has_granules_created_at\\[\\]=2015-01-01T19:00:00Z,\"\n",
    "\n",
    "# Product information for the MODIS products I want\n",
    "shortname_id = \"short_name=MOD021KM\" # \"short_name=MOD03\"\n",
    "version = \"version=6.1\"\n",
    "\n",
    "# bounding box around the study area I want to look at (upper Tuolumne River basin)\n",
    "# lower left longitude, lower left latitude, upper right longitude, upper right latitude\n",
    "bounding_box = \"bounding_box[]=-120,37,-118,38\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty list to hold modis download URLs\n",
    "modis_urls = []\n",
    "\n",
    "for i, this_timestamp in enumerate(aster.timestampUTC):\n",
    "       \n",
    "    # the date is the first 10 characters of the timestamp string\n",
    "    date = this_timestamp[:10]\n",
    "    #print(date)\n",
    "    \n",
    "    \n",
    "    # Terra ASTER/MODIS is always flying over here at ~18:50 UTC (day) or ~5:50 UTC (night)\n",
    "    hours = [(18, 19), (5, 6)]\n",
    "    for h in hours:\n",
    "        start_time = \"{date}T{hour_start}:00:00Z\".format(date=date,hour_start=h[0])\n",
    "        end_time = \"{date}T{hour_end}:00:00Z\".format(date=date,hour_end=h[1])\n",
    "        time_range = \"temporal=\" + start_time + \",\" + end_time\n",
    "    \n",
    "        # build the whole request URL and make the request.get\n",
    "        response = requests.get(url+\"&\"+shortname_id+\"&\"+version+\"&\"+bounding_box+\"&\"+time_range)\n",
    "    \n",
    "        # read the response CSV and put in a temporary dataframe\n",
    "        df = pd.read_csv(io.StringIO(response.text))\n",
    "        \n",
    "        for modis_url in df['Online Access URLs']:\n",
    "            modis_urls.append(modis_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the list of URLs out to a text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"modis_download_list.txt\", \"w\") as output:\n",
    "    for row in modis_urls:\n",
    "        output.write(str(row) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Download using wget**\n",
    "\n",
    "`wget --http-user=YOUR_USERNAME --ask-password --keep-session-cookies --auth-no-challenge=on -c -i modis_download_list.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### *WORK IN PROGRESS*\n",
    "\n",
    "**Convert HDF to GeoTiff**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, get filepaths for the MODIS observations I've just now downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for MODIS files in this directory\n",
    "modis_dir = '/storage/MODIS/Tuolumne_MOD021KM/'\n",
    "# get .hdf files here\n",
    "modis_filelist = glob.glob(modis_dir + '*.hdf', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "from pyproj import Transformer\n",
    "from affine import Affine\n",
    "from rioxarray.rioxarray import affine_to_coords\n",
    "\n",
    "def modis_hdf2geotiff(modis_filename, modis_variable, output_filename):\n",
    "    \n",
    "    '''Convert a MODIS HDF file to GeoTiff and reproject following this method: https://gis.stackexchange.com/questions/345691/using-python-gdal-to-reproject-an-hdf'''\n",
    "    \n",
    "    modis_crs_str = \"+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs\"\n",
    "    \n",
    "    rds = rioxarray.open_rasterio(modis_filename,\n",
    "                                  variable=[modis_variable],\n",
    "                                  parse_coordinates=False)\n",
    "    \n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", modis_crs_str, always_xy=True)\n",
    "    west, north = transformer.transform(rds.WESTBOUNDINGCOORDINATE, rds.NORTHBOUNDINGCOORDINATE)\n",
    "    \n",
    "    pixel_size = 1000 # 1 km\n",
    "    transform = Affine(pixel_size, 0, west, 0, -pixel_size, north)\n",
    "    \n",
    "    coords = affine_to_coords(transform, rds.rio.width, rds.rio.height)\n",
    "    rds.coords[\"x\"] = coords[\"x\"]\n",
    "    rds.coords[\"y\"] = coords[\"y\"]\n",
    "    \n",
    "    # add the CRS\n",
    "    rds.rio.write_crs(modis_crs_str, inplace=True)\n",
    "    \n",
    "    rds4326 = rds.rio.reproject(\"EPSG:4326\")\n",
    "    \n",
    "    # write out to geotiff file\n",
    "    rds4326[modis_variable].rio.to_raster(output_filename)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modis_variable = \"4\"\n",
    "\n",
    "for i in range(len(modis_filelist)):\n",
    "    fn = \"{}\".format(modis_filelist[i])\n",
    "    new_fn = \"{}.tif\".format(modis_filelist[i][:-4])\n",
    "    print('\\nConverting {} to {}\\n'.format(fn, new_fn))\n",
    "    modis_hdf2geotiff(fn, modis_variable, new_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goes-linux",
   "language": "python",
   "name": "goes-linux"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
