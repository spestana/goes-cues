{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating GOES images with coincident MODIS and ASTER**\n",
    "\n",
    "What are the magnitude and distribution of differences between ABI-ASTER & MODIS-ASTER?\n",
    "* Is there an East-to-West change in differences?\n",
    "* Is there a North-to-South change in differences?\n",
    "* Is there a relationship between differences and elevation, slope, or aspect?\n",
    "* Is there a relationship between differences and fractional vegetation covered area?\n",
    "* Is there a relationship between differences and fractional snow covered area? (from coincident MODIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from xhistogram.xarray import histogram\n",
    "import richdem as rd\n",
    "import rioxarray as rxr\n",
    "import xrspatial as xrs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import glob\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pysolar\n",
    "import datetime\n",
    "\n",
    "from asp_binder_utils import get_dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_stats(a, b):\n",
    "    '''Compute summary statistics for the difference between two sets.\n",
    "    Input two flattened (1-D) arrays with NaN values removed'''\n",
    "    \n",
    "    # remove nan values\n",
    "    a = a[np.isnan(a)==False]\n",
    "    b = b[np.isnan(b)==False]\n",
    "    \n",
    "    # for difference stats\n",
    "    diff = b - a\n",
    "    \n",
    "    # for linear regression stats\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(a, b)\n",
    "    \n",
    "    # populate dict with summary stats\n",
    "    summary_stats_dict = {\n",
    "        #'diff' : diff ,\n",
    "        'n' : len(diff) ,\n",
    "        'mean_diff' : np.nanmean( diff ),\n",
    "        'median_diff' : np.nanmedian( diff ),\n",
    "        'mean_squared_diff' : np.nanmean( diff**2 ),\n",
    "        'rms_diff' : np.sqrt( np.nanmean( diff**2 ) ),\n",
    "        'std_diff' : np.nanstd( diff ),\n",
    "        'slope' : slope,\n",
    "        'intercept' : intercept,\n",
    "        'r_value' : r_value,\n",
    "        'p_value' : p_value,\n",
    "        'std_err' : std_err\n",
    "        }\n",
    "    \n",
    "    return summary_stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression_confidence_intervals(_x,_y,conf):\n",
    "\n",
    "    # linear regression\n",
    "    slope, intercept, r, p, se = stats.linregress(_x, _y)\n",
    "    \n",
    "    # predict y values of origional data using the fit\n",
    "    p_y = slope*_x + intercept\n",
    "    \n",
    "    # calculate the y-error (residuals)\n",
    "    y_err = _y - p_y\n",
    "    \n",
    "    # create series of new test x-values to predict for\n",
    "    p_x = np.arange(np.min(_x),np.max(_x)+1,1)\n",
    "    \n",
    "    # now calculate confidence intervals for new test x-series\n",
    "    mean_x = np.mean(_x)                 # mean of x\n",
    "    n = _x.size                          # number of samples in original fit\n",
    "    t = stats.t.ppf(conf, n-2)            # find the appropriate t value (for n-2, and two tailed 95%)        \n",
    "    sse = np.sum(y_err**2)              # sum of the squares of the residuals\n",
    "    st_err = np.sqrt(sse/(n-2))         # standard error\n",
    "    \n",
    "    sigma = st_err**2 * (1 + 1/n + ( ( n*(p_x-mean_x)**2 ) / ( n*np.sum(_x**2) - np.sum(_x)**2 ) ) )\n",
    "    confs = t * np.sqrt(sigma)\n",
    "    \n",
    "    # now predict y based on test x-values\n",
    "    p_y = slope*p_x + intercept\n",
    "    \n",
    "    # get lower and upper confidence limits based on predicted y and confidence intervals\n",
    "    lower = p_y - np.abs(confs)\n",
    "    upper = p_y + np.abs(confs)\n",
    "    \n",
    "    # plot line of best fit\n",
    "    c_x = np.array([_x.min(),_x.max()])\n",
    "    c_y = slope*c_x + intercept\n",
    "    plt.plot(c_x,c_y,'r--',label='Regression line')\n",
    "    \n",
    "    # plot confidence limits\n",
    "    plt.plot(p_x,lower,':',c='grey',label='Lower confidence limit (95%)')\n",
    "    plt.plot(p_x,upper,':',c='grey',label='Upper confidence limit (95%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 16\n",
    "MEDIUM_SIZE = 16\n",
    "BIGGER_SIZE = 18\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Make dataset\n",
    "\n",
    "First I need to make a combined dataset to make these investigations easier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONAL: Read in the ground based data timeseries for Gaylor Pit and CUES sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gaylor Pit\n",
    "#tuol_df = pd.read_pickle('data/goes-tuolumne_2017-2020.pkl')\n",
    "#tuol_df['timeUTC'] = tuol_df.index + pd.Timedelta(hours=8)\n",
    "#tuol_df.set_index('timeUTC',inplace=True)\n",
    "#tuol_ds = tuol_df.to_xarray().squeeze()\n",
    "#\n",
    "## CUES\n",
    "#cues_df = pd.read_pickle('data/goes-cues_2017-2020.pkl')\n",
    "#cues_df['timeUTC'] = cues_df.index + pd.Timedelta(hours=8)\n",
    "#cues_df.set_index('timeUTC',inplace=True)\n",
    "#cues_ds = cues_df.to_xarray().squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up working area geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Larger area around Tuolumne further south and east to include Mammoth\n",
    "(utm_e_UL, utm_n_UL) = 282500, 4205000\n",
    "(utm_e_UR, utm_n_UR) = 305000, 4205000\n",
    "(utm_e_LR, utm_n_LR) = 327500, 4160000\n",
    "(utm_e_LL, utm_n_LL) = 305000, 4160000\n",
    "\n",
    "geometry = [\n",
    "    {\n",
    "        'type': 'Polygon',\n",
    "        'coordinates': [[\n",
    "            [utm_e_UL, utm_n_UL],\n",
    "            [utm_e_UR, utm_n_UR],\n",
    "            [utm_e_LR, utm_n_LR],\n",
    "            [utm_e_LL, utm_n_LL]\n",
    "        ]]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find datasets (orthorectified GOES ABI or original GOES ABI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepaths = glob.glob('/storage/spestana/output_ASTER-MODIS-GOES/*_orthorectified.nc')\n",
    "##filepaths = glob.glob('/storage/spestana/output_ASTER-MODIS-GOES/*_original.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = xr.open_mfdataset(filepaths, concat_dim='time', combine='nested')\n",
    "######ds = ds.rio.clip(geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open my DEM, reproject to UTM, add to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dem = xr.open_rasterio('dem/tuolumne_cues_dem.tif').rio.reproject_match(ds)\n",
    "#ds['dem'] = dem.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLD, skip this: Compute slope and aspect and add to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dem_array = rd.rdarray(ds.dem.values, no_data=np.nan).squeeze()\n",
    "#slope = rd.TerrainAttribute(dem_array, attrib='slope_riserun')\n",
    "#ds['slope'] = (['y','x'], slope)\n",
    "#aspect = rd.TerrainAttribute(dem_array, attrib='aspect')\n",
    "#ds['aspect'] = (['y','x'], aspect)\n",
    "## aspect looks like it puts 0=360 at East not north. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Create fractional vegetated area from TCC via a binary vegetation map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def fveg_mapZonalStats(zones, zonalstats, stat_name):\n",
    "#    ''' Function for mapping the zonal statistics back to the original grid to get a 2D map of the chosen statistic'''\n",
    "#    # create an empty array for this summary stat\n",
    "#    zonal_stat = np.zeros_like(zones.values, dtype=np.float64)\n",
    "#\n",
    "#    # for each zone\n",
    "#    for zone_n in zonalstats.index.values:\n",
    "#        # get the summary stat for that zone, \n",
    "#        # and assign it to the correct locations in the zonal_stat array\n",
    "#        #try:\n",
    "#        zonal_stat[zones.values==zone_n] = zonalstats['{}'.format(stat_name)].loc[zone_n]\n",
    "#        #except: #MaskError: Cannot convert masked element to a Python int.\n",
    "#        #    zonal_stat[zones.values==zone_n] = -9999\n",
    "#\n",
    "#    # convert this to an xarray data array with the proper name\n",
    "#    zonal_stat_da = xr.DataArray(zonal_stat, \n",
    "#                                 dims=[\"y\", \"x\"],\n",
    "#                                 coords=dict(\n",
    "#                                             x=([\"x\"], zones.x),\n",
    "#                                             y=([\"y\"], zones.y),\n",
    "#                                             ),\n",
    "#                                 name='zonal_{}'.format(stat_name))\n",
    "#    # remove nodata values\n",
    "#    zonal_stat_da = zonal_stat_da.where(zonal_stat_da!=-9999, np.nan)\n",
    "#\n",
    "#    return zonal_stat_da     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open TCC and add to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tcc = xr.open_rasterio('data/NLCD_2016_Tree_Canopy_L48_20190831_2xOlzdukUemPqURl8ckP.tiff').rio.reproject_match(ds)\n",
    "#tcc = tcc.where(tcc!=tcc._FillValue)\n",
    "#ds['tcc'] = tcc.squeeze()\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New version: making fveg from binary tcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def tcc_to_binary_forest(tcc, threshold):\n",
    "#    \n",
    "#    intermediate_map = tcc.where((np.isnan(tcc))|(tcc>threshold),0)\n",
    "#    \n",
    "#    binary_forest = intermediate_map.where((np.isnan(intermediate_map))|(intermediate_map<threshold), 1)\n",
    "#    \n",
    "#    return binary_forest\n",
    "#\n",
    "#ds['binary_tcc_gt10'] = tcc_to_binary_forest(tcc, 10).squeeze()\n",
    "#ds['binary_tcc_gt20'] = tcc_to_binary_forest(tcc, 20).squeeze()\n",
    "#ds['binary_tcc_gt30'] = tcc_to_binary_forest(tcc, 30).squeeze()\n",
    "#ds['binary_tcc_gt40'] = tcc_to_binary_forest(tcc, 40).squeeze()\n",
    "#ds['binary_tcc_gt50'] = tcc_to_binary_forest(tcc, 50).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot an image of this if we want to inspect what our choice of threshold did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(40,20))\n",
    "#[ax1, ax2, ax3, ax4, ax5, ax6] = axs.ravel()\n",
    "#\n",
    "#ds.binary_tcc_gt10.where(ds.binary_tcc_gt10!=0).plot(cmap='spring',alpha=1, ax=ax1, add_colorbar=False)\n",
    "#ds.binary_tcc_gt20.where(ds.binary_tcc_gt20!=0).plot(cmap='spring',alpha=1, ax=ax2, add_colorbar=False)\n",
    "#ds.binary_tcc_gt30.where(ds.binary_tcc_gt30!=0).plot(cmap='spring',alpha=1, ax=ax3, add_colorbar=False)\n",
    "#ds.binary_tcc_gt40.where(ds.binary_tcc_gt40!=0).plot(cmap='spring',alpha=1, ax=ax4, add_colorbar=False)\n",
    "#ds.binary_tcc_gt50.where(ds.binary_tcc_gt50!=0).plot(cmap='spring',alpha=1, ax=ax5, add_colorbar=False)\n",
    "#\n",
    "#for ax in  [ax1, ax2, ax3, ax4, ax5]:\n",
    "#    tcc.plot(ax=ax, cmap='Greys_r', add_colorbar=False, zorder=-99)\n",
    "#    ax.set_ylim((4.18e6,4.20e6))\n",
    "#    ax.set_xlim((290000,310000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to base my binary forest map on a threshold of 30% TCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#da_fveg_mean_stack = []\n",
    "#for i in range(0,len(ds.time)):\n",
    "#    fveg_mean = ds.isel(time=i).groupby('ast_goes_goes_zones').mean().binary_tcc_gt30.to_dataframe()\n",
    "#    da_fveg_mean = fveg_mapZonalStats(ds.isel(time=i).ast_goes_goes_zones, fveg_mean, 'binary_tcc_gt30')\n",
    "#    da_fveg_mean_stack.append(da_fveg_mean)\n",
    "#    \n",
    "#ds_fveg_mean = xr.concat(da_fveg_mean_stack, 'time' )\n",
    "#ds['fveg'] = ds_fveg_mean.where(~np.isnan(ds.ast_goes_goes_zones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Old version: Making fveg from tcc mean\n",
    "\n",
    "###fveg = (tcc - tcc.min()) / (tcc.max() - tcc.min()) # normalizing tcc to get fveg\n",
    "###ds['fveg'] = fveg.squeeze()\n",
    "###\n",
    "###da_fveg_mean_stack = []\n",
    "###for i in range(0,len(ds.time)):\n",
    "###    fveg_mean = ds.isel(time=i).groupby('ast_goes_goes_zones').mean().fveg.drop(['spatial_ref','band','time']).to_dataframe()\n",
    "###    da_fveg_mean = fveg_mapZonalStats(ds.isel(time=i).ast_goes_goes_zones, fveg_mean, 'fveg')\n",
    "###    da_fveg_mean_stack.append(da_fveg_mean)\n",
    "###    \n",
    "###ds_fveg_mean = xr.concat(da_fveg_mean_stack, 'time' )\n",
    "###ds['zonal_mean_fveg'] = ds_fveg_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save out datafile to a single netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds.to_netcdf('/storage/spestana/ASTER-MODIS-GOES-DEM-FVEG_v3_orthorectified.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Open dataset (if already created above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('/storage/spestana/ASTER-MODIS-GOES-DEM-FVEG_v3_orthorectified.nc')\n",
    "ds = ds.rio.clip(geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### download another dem to compute slope/aspect/hillshade/etd with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dem(demtype='SRTMGL3', \n",
    "        bounds=(-120, 36 , -118, 40), \n",
    "        out_fn='dem_4.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_elevation = rxr.open_rasterio('dem_4.tif')\n",
    "dem_elevation = dem_elevation.rio.reproject_match(ds.dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "dem_elevation.plot(ax=ax, vmin=1300, vmax=4000, cmap='terrain')\n",
    "ax.axis('off')\n",
    "ax.set_title('')\n",
    "ax.plot([utm_e_UL, utm_e_UR, utm_e_LR, utm_e_LL, utm_e_UL],\n",
    "                 [utm_n_UL, utm_n_UR, utm_n_LR, utm_n_LL, utm_n_UL],\n",
    "                 linestyle='--', color='w', lw=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Aspect Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdaldem aspect dem_4.tif aspect_4.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_aspect = rxr.open_rasterio('aspect_4.tif')\n",
    "dem_aspect = dem_aspect.rio.reproject_match(ds.dem)\n",
    "dem_aspect = dem_aspect.where(dem_aspect != -9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "dem_aspect.plot(ax=ax, cmap='hsv')\n",
    "ax.axis('off')\n",
    "ax.set_title('')\n",
    "ax.plot([utm_e_UL, utm_e_UR, utm_e_LR, utm_e_LL, utm_e_UL],\n",
    "                 [utm_n_UL, utm_n_UR, utm_n_LR, utm_n_LL, utm_n_UL],\n",
    "                 linestyle='-', color='k', lw=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add aspect to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['dem_aspect'] = dem_aspect.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Slope Map (need to reproject first into UTM so we compute vertical meters / horizontal meters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdalwarp -t_srs EPSG:32611 dem_4.tif dem_4utm.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdaldem slope dem_4utm.tif slope_4.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_slope = rxr.open_rasterio('slope_4.tif')\n",
    "dem_slope = dem_slope.rio.reproject_match(ds.dem)\n",
    "dem_slope = dem_slope.where(dem_slope != -9999.) \n",
    "#dem_slope = dem_slope.where(dem_slope != -9999)\n",
    "#dem_slope = dem_slope.where(dem_slope != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "dem_slope.plot(ax=ax, cmap='Greys_r')\n",
    "ax.axis('off')\n",
    "ax.set_title('')\n",
    "ax.plot([utm_e_UL, utm_e_UR, utm_e_LR, utm_e_LL, utm_e_UL],\n",
    "                 [utm_n_UL, utm_n_UR, utm_n_LR, utm_n_LL, utm_n_UL],\n",
    "                 linestyle='--', color='w', lw=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add slope to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['dem_slope'] = dem_slope.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Hillshade function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hillshade(slope, aspect, zenith, azimuth):\n",
    "    slope_rad = np.radians(slope)\n",
    "    aspect_rad = np.radians(aspect)\n",
    "    zenith_rad = np.radians(zenith)\n",
    "    azimuth_rad = np.radians(azimuth)\n",
    "    hillshade = np.cos(zenith_rad)*np.cos(slope_rad) + np.sin(zenith_rad)*np.sin(slope_rad)*np.cos(azimuth_rad - aspect_rad)\n",
    "    return hillshade\n",
    "\n",
    "### Test hillshade function\n",
    "#_slopes = np.array([np.arange(0,90,1)]*360).T\n",
    "#_aspects = np.array([np.arange(0,360,1)]*90)\n",
    "#\n",
    "#test_hs = hillshade(_slopes, _aspects, 45, 90)\n",
    "#\n",
    "#plt.pcolormesh(test_hs,vmin=-1,vmax=1,cmap='RdBu_r')\n",
    "#plt.colorbar(label='hillshade')\n",
    "#plt.ylabel('slope')\n",
    "#plt.xlabel('aspect')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for computing GOES Local Zenith Angles, and Azimuth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goes_lza(lat_ssp, lon_ssp, lat, lon, H=42164.16, r_eq=6378.137):\n",
    "    \n",
    "    '''\n",
    "    Compute the Locan Zenith Angle for a point on Earth surface to a GOES-R geostationary satellite.\n",
    "        See more details from NOAA here: \n",
    "        https://www.ncdc.noaa.gov/sites/default/files/attachments/GOES-R_ABI_local_zenith_angle_description.docx\n",
    "    \n",
    "    Inputs:\n",
    "        GOES-R satellite position\n",
    "            lat_ssp: sub-satellite point latitude [degrees]\n",
    "            lon_ssp: sub-satellite point longitude [degrees]\n",
    "    \n",
    "        View point (on Earth's surface) position\n",
    "            lat: view point latitude on Earth's surfaace [degrees]\n",
    "            lon: view point longitude on Earth's surface [degrees]\n",
    "            elev: view point elevation (heigh above GRS80 ellispoid) [km]\n",
    "            \n",
    "        Earth model parameters (optional)\n",
    "            H: satellite distance to Earth center [km] (defaults to 42164.16 km)\n",
    "            r_eq: Earth semi-major axis (GRS80 ellipsoid) [km] (defaults to 6378.137 km)\n",
    "            \n",
    "    Returns:\n",
    "        LZA: local zenith angle [degrees]\n",
    "        is_point_visible: True/False flag indicating if the ground point is actually visible to the satellite\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # intermediate calculation\n",
    "    B = np.arccos( np.cos(np.radians(lat)-np.radians(lat_ssp)) * np.cos(np.radians(lon)-np.radians(lon_ssp)) )\n",
    "\n",
    "    # determine if point is visible to the satellite\n",
    "    is_point_visible = (B < np.arccos(r_eq / (H+r_eq)))\n",
    "\n",
    "    # compute LZA\n",
    "    LZA_radians = np.arcsin( (H * np.sin(B) ) / ( np.sqrt( H**2 + r_eq**2 - 2*H*r_eq*np.cos(B) ) ) )\n",
    "    \n",
    "    # convert LZA from radians to degrees\n",
    "    LZA = LZA_radians * 180/np.pi\n",
    "    \n",
    "    return LZA, is_point_visible\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def goes_azi(lat_ssp, lon_ssp, lat, lon):\n",
    "    \n",
    "    '''quick calculation of azimuth for geostationary satellite, not GOES specific, spherical Earth assumption\n",
    "    http://tiij.org/issues/issues/3_2/3_2e.html'''\n",
    "    \n",
    "    azi = 180 + np.degrees( np.arctan(np.tan(np.radians(lon_ssp - lon))/np.sin(np.radians(lat))) )\n",
    "    \n",
    "    return azi.T\n",
    "\n",
    "\n",
    "\n",
    "def diurnal_anisotropic_heat(aspect, slope, a_max):\n",
    "    '''\n",
    "    Make a Diurnal Anisotropic Heating (DAH) index (Böhner & Antonic, 2009)\n",
    "        a_max = 202.5 (SSW) from Cristea et al., 2017 in Tuolumne area\n",
    "    '''\n",
    "    DAH = np.cos(np.radians(a_max - aspect)) * np.arctan(np.radians(slope))\n",
    "    return DAH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute LZA and Azimuth maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when t is 0,1,2,3,4... ssp_lon = -89.5\n",
    "\n",
    "# for satellite+terrain geometry maps\n",
    "list_of_satellite_lza_maps = []\n",
    "list_of_satellite_azi_maps = []\n",
    "list_of_satellite_hillshade_maps = []\n",
    "\n",
    "# for solar+terrain geometry maps\n",
    "list_of_solar_lza_maps = []\n",
    "list_of_solar_azi_maps = []\n",
    "list_of_solar_hillshade_maps = []\n",
    "list_of_dah_maps = []\n",
    "\n",
    "for t_idx, this_t in enumerate(ds.time):\n",
    "    \n",
    "    lat_ssp = 0 # on the equator\n",
    "    \n",
    "    # first 5 observations GOES-16 was in the -89.5 \"test\" orbital slot, thereafter at -75.2 lon\n",
    "    if t_idx <= 4:\n",
    "        lon_ssp = -89.5\n",
    "    else:\n",
    "        lon_ssp = -75.2\n",
    "    \n",
    "    # make satellite local zenith angle map\n",
    "    this_lza_map, this_visible = goes_lza(lat_ssp, lon_ssp, dem_latlon.y, dem_latlon.x)\n",
    "    this_lza_map = this_lza_map.rio.reproject_match(ds.dem)\n",
    "    list_of_satellite_lza_maps.append(this_lza_map)\n",
    "    \n",
    "    # make satellite azimuth angle map\n",
    "    this_azi_map = goes_azi(lat_ssp, -lon_ssp, dem_latlon.y, -dem_latlon.x) # right now this counts positive in the west direction\n",
    "    this_azi_map = this_azi_map.rio.reproject_match(ds.dem)\n",
    "    list_of_satellite_azi_maps.append(this_azi_map)\n",
    "    \n",
    "    # make satellite hillshade map\n",
    "    this_sat_hillshade_map = hillshade(ds.dem_slope, ds.dem_aspect, this_lza_map, this_azi_map)\n",
    "    list_of_satellite_hillshade_maps.append(this_sat_hillshade_map)\n",
    "    \n",
    "    # do np.datetime64 -> datetime.datetime conversion for solar maps\n",
    "    this_datetime = pd.Timestamp( this_t.values, tzinfo=datetime.timezone.utc )\n",
    "\n",
    "    # make solar local zenith angle map\n",
    "    solar_altitude_deg = pysolar.solar.get_altitude(dem_latlon.y, dem_latlon.x, this_datetime).transpose('y', 'x')\n",
    "    solar_altitude_deg = solar_altitude_deg.rio.reproject_match(ds.dem)\n",
    "    solar_lza_deg = 90 - solar_altitude_deg # subtract 90 degrees from elevation angle to get zenith angle\n",
    "    list_of_solar_lza_maps.append(solar_lza_deg)\n",
    "    \n",
    "    # make solar azimuth angle map\n",
    "    solar_azimuth_deg = pysolar.solar.get_azimuth(dem_latlon.y, dem_latlon.x, this_datetime).transpose('y', 'x')\n",
    "    solar_azimuth_deg = solar_azimuth_deg.rio.reproject_match(ds.dem)\n",
    "    list_of_solar_azi_maps.append(solar_azimuth_deg)\n",
    "    \n",
    "    # make solar hillshade map\n",
    "    this_solar_hillshade_map = hillshade(ds.dem_slope, ds.dem_aspect, solar_lza_deg, solar_azimuth_deg)\n",
    "    list_of_solar_hillshade_maps.append(this_solar_hillshade_map)\n",
    "    \n",
    "    # make Diurnal Anisotropic Heating index map\n",
    "    this_DAH = diurnal_anisotropic_heat(ds.dem_aspect, ds.dem_slope, solar_azimuth_deg)\n",
    "    list_of_dah_maps.append(this_DAH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add all these satellite and solar LZA, Azi, Hillshade, and DAH maps to our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# satellite\n",
    "ds['sat_azimuth'] = xr.concat(list_of_satellite_azi_maps, 'time')\n",
    "ds['sat_lza'] = xr.concat(list_of_satellite_lza_maps, 'time')\n",
    "ds['sat_hillshade'] = xr.concat(list_of_satellite_hillshade_maps, 'time')\n",
    "\n",
    "# solar\n",
    "ds['solar_azimuth'] = xr.concat(list_of_solar_azi_maps, 'time')\n",
    "ds['solar_lza'] = xr.concat(list_of_solar_lza_maps, 'time')\n",
    "ds['solar_hillshade'] = xr.concat(list_of_solar_hillshade_maps, 'time')\n",
    "ds['DAH'] = xr.concat(list_of_dah_maps, 'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this version out\n",
    "ds.to_netcdf('/storage/spestana/ASTER-MODIS-GOES-DEM-FVEG_v4_orthorectified.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just an example, or to make an illustrative plot of GOES ABI LZA and Azimuth\n",
    "\n",
    "#dem_latlon = rxr.open_rasterio('dem_4.tif') # need to open the dem in its WGS84 lat/lon projection\n",
    "#lza_map, visible = goes_lza(0, -75.2, dem_latlon.y, dem_latlon.x)\n",
    "#lza_map = lza_map.rio.reproject_match(ds.dem)\n",
    "#\n",
    "#azimuth_map = goes_azi(0, 75.2, dem_latlon.y, -dem_latlon.x)\n",
    "#azimuth_map = azimuth_map.rio.reproject_match(ds.dem)\n",
    "#\n",
    "#\n",
    "#fig, ax = plt.subplots(figsize=(6,5))\n",
    "#lza_map.plot(ax=ax)\n",
    "#ax.axis('off')\n",
    "#ax.set_title(f'mean LZA = {np.round(np.mean(lza_map).values,2)}')\n",
    "#ax.plot([utm_e_UL, utm_e_UR, utm_e_LR, utm_e_LL, utm_e_UL],\n",
    "#                 [utm_n_UL, utm_n_UR, utm_n_LR, utm_n_LL, utm_n_UL],\n",
    "#                 linestyle='--', color='w', lw=3)\n",
    "#\n",
    "#fig, ax = plt.subplots(figsize=(6,5))\n",
    "#azimuth_map.plot(ax=ax)\n",
    "#ax.axis('off')\n",
    "#ax.set_title(f'mean AZI = {np.round(np.mean(azimuth_map).values,2)}')\n",
    "#ax.plot([utm_e_UL, utm_e_UR, utm_e_LR, utm_e_LL, utm_e_UL],\n",
    "#                 [utm_n_UL, utm_n_UR, utm_n_LR, utm_n_LL, utm_n_UL],\n",
    "#                 linestyle='--', color='w', lw=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute two hillshades\n",
    "* **hs_sat** for the satellite's view\n",
    "* **hs_sun** for solar illumination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hs_sat = hillshade(dem_slope, dem_aspect, lza_map, azimuth_map)\n",
    "#hs_sat = hs_sat.rio.clip(geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(figsize=(6,5))\n",
    "#hs_sat.plot(cmap='Greys_r',vmin=0,vmax=1,ax=ax,alpha=1)\n",
    "#ax.axis('off')\n",
    "#ax.set_title('')\n",
    "#ax.plot([utm_e_UL, utm_e_UR, utm_e_LR, utm_e_LL, utm_e_UL],\n",
    "#                 [utm_n_UL, utm_n_UR, utm_n_LR, utm_n_LL, utm_n_UL],\n",
    "#                 linestyle='-', color='k', lw=3);\n",
    "#\n",
    "#fig, ax = plt.subplots(figsize=(6,5))\n",
    "#hs_sat.plot(cmap='Greys_r',vmin=0,vmax=1,ax=ax,alpha=1)\n",
    "#hs_sat.where(hs_sat<=0).plot(cmap='spring',vmin=0,vmax=1,ax=ax,alpha=1, add_colorbar=False)\n",
    "#ax.axis('off')\n",
    "#ax.set_title('')\n",
    "#ax.plot([utm_e_UL, utm_e_UR, utm_e_LR, utm_e_LL, utm_e_UL],\n",
    "#                 [utm_n_UL, utm_n_UR, utm_n_LR, utm_n_LL, utm_n_UL],\n",
    "#                 linestyle='-', color='k', lw=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Sunlight hillshade maps\n",
    "* use pysolar to get sun positions for each DEM gridcell for each of the 27 date/times of GOES observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##date = datetime.datetime(2007, 2, 18, 18, 59, 59, tzinfo=datetime.timezone.utc)\n",
    "#dates = [pd.Timestamp( this_date, tzinfo=datetime.timezone.utc ) for this_date in ds.time.values]\n",
    "#date = dates[1]\n",
    "#\n",
    "#longitude = dem_latlon.x\n",
    "#latitude = dem_latlon.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solar_altitude_deg = pysolar.solar.get_altitude(latitude, longitude, date).transpose('y', 'x')\n",
    "#solar_altitude_deg = solar_altitude_deg.rio.reproject_match(ds.dem)\n",
    "#solar_lza_deg = 90 - solar_altitude_deg\n",
    "##.rio.clip(geometry)\n",
    "#\n",
    "#solar_azimuth_deg = pysolar.solar.get_azimuth(latitude, longitude, date).transpose('y', 'x')\n",
    "#solar_azimuth_deg = azimuth_deg.rio.reproject_match(ds.dem)\n",
    "##.rio.clip(geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(figsize=(6,5))\n",
    "#solar_lza_deg.plot(ax=ax,alpha=1)\n",
    "#ax.axis('off')\n",
    "#ax.set_title(f'Solar LZA {date}')\n",
    "#ax.plot([utm_e_UL, utm_e_UR, utm_e_LR, utm_e_LL, utm_e_UL],\n",
    "#                 [utm_n_UL, utm_n_UR, utm_n_LR, utm_n_LL, utm_n_UL],\n",
    "#                 linestyle='--', color='w', lw=3);\n",
    "#\n",
    "#fig, ax = plt.subplots(figsize=(6,5))\n",
    "#solar_azimuth_deg.plot(ax=ax,alpha=1)\n",
    "#ax.axis('off')\n",
    "#ax.set_title(f'Solar Azimuth {date}')\n",
    "#ax.plot([utm_e_UL, utm_e_UR, utm_e_LR, utm_e_LL, utm_e_UL],\n",
    "#                 [utm_n_UL, utm_n_UR, utm_n_LR, utm_n_LL, utm_n_UL],\n",
    "#                 linestyle='--', color='w', lw=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute solar hillshade for date/time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hs_sun = hillshade(dem_slope, dem_aspect, solar_lza_deg, solar_azimuth_deg)\n",
    "#hs_sun = hs_sun.rio.clip(geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(figsize=(6,5))\n",
    "#hs_sun.plot(cmap='Greys_r',vmin=0,vmax=1,ax=ax,alpha=1)\n",
    "#hs_sun.where(hs_sun<=0).plot(cmap='spring',vmin=0,vmax=1,ax=ax,alpha=1, add_colorbar=False)\n",
    "#ax.axis('off')\n",
    "#ax.set_title('')\n",
    "#ax.plot([utm_e_UL, utm_e_UR, utm_e_LR, utm_e_LL, utm_e_UL],\n",
    "#                 [utm_n_UL, utm_n_UR, utm_n_LR, utm_n_LL, utm_n_UL],\n",
    "#                 linestyle='-', color='k', lw=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a Diurnal Anisotropic Heating index \n",
    "* DAH from (Böhner & Antonic, 2009)\n",
    "* $\\alpha_{max} = 202.5^o (SSW)$ from Cristea et al., 2017 in Tuolumne area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DAH = diurnal_anisotropic_heat(dem_aspect, dem_slope, solar_azimuth_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(figsize=(6,5))\n",
    "#DAH.plot(ax=ax,alpha=1)\n",
    "#ax.axis('off')\n",
    "#ax.set_title(f'DAH')\n",
    "#ax.plot([utm_e_UL, utm_e_UR, utm_e_LR, utm_e_LL, utm_e_UL],\n",
    "#                 [utm_n_UL, utm_n_UR, utm_n_LR, utm_n_LL, utm_n_UL],\n",
    "#                 linestyle='-', color='k', lw=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goes-linux",
   "language": "python",
   "name": "goes-linux"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
